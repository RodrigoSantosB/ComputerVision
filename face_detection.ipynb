{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/home/rsb6/Desktop/ComputerVision/eyes.png\" alt=\"eyes points\" width=\"1180\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the librarys\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O EAR é dado pelo valor da distância euclidiana entre o ponto P2 e o ponto P6, mais o valor da distância euclidiana entre o ponto P3 e o ponto P5. Isso tudo sobre duas vezes a distância euclidiana entre o ponto P1 e o ponto P4.\n",
    "\n",
    "$$EAR =\\Large {\\frac{(|| p_2 - p_6|| + ||p_3-p_5||)}{2*||p_1-p_2||}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando a equação para as coordenadas de ambos os olhos\n",
    "\n",
    "$$EAR_{right} =  \\Large {\\frac{||p_160-p_144|| + ||p_158-p_153||}{2*||p_33 - p_133||}}$$\n",
    "\n",
    "$$EAR_{lefth} =  \\Large {\\frac{||p_385-p_380|| + ||p_387-p_373||}{2*||p_362 - p_263||}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo recomendado para qualquer projeto é realizar uma análise: verificar possíveis problemas e pensar em ajustes para eles.\n",
    "\n",
    "Vamos rodar a célula em que produzimos nosso código de verificação de EAR e fazer essa análise. Se eu fecho meus olhos, o tempo passa a ser contado e uma mensagem de alerta aparece caso permaneça com os olhos fechados por muito tempo.\n",
    "\n",
    "No entanto, se eu estiver sorrindo, dando uma gargalhada, meus olhos ficarão semi cerrados. Isso faz com que o nosso código entenda que os olhos estão fechados. Vou fazer o teste sorrindo. A mensagem apareceu.\n",
    "\n",
    "Precisamos verificar a abertura da boca, porque quase ninguém dorme sorrindo ou gargalhando. Geralmente, as pessoas dormem com o rosto relaxado. Agora fecharemos a janela de vídeo e calcularemos a abertura da boca. Para isso, utilizamos os pontos da boca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/home/rsb6/Desktop/ComputerVision/mouth.png\" alt=\"mouth points\" width=\"1180\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 8 pontos especificamente na boca. Nós realizaremos um cálculo similar ao EAR, utilizando esses pontos. O MAR ou Mouth Aspect Ratio (Em tradução livre: Proporção da boca) funciona exatamente como o EAR, mas para as coordenadas da boca.\n",
    "\n",
    "Nosso primeiro passo é encontrar os pontos que estão indicados na imagem no MediaPipe. Então, temos que identificar esses pontos e mostrá-los na tela, assim como fizemos para o EAR.\n",
    "\n",
    "Então, criaremos uma nova célula acima da célula de projeto. Dentro dela, faremos uma lista com os pontos da boca, exatamente os que são indicados na imagem do notebook: `82, 87, 13, 14, 312, 317, 308 e 78.`\n",
    "\n",
    "O cálculo do índice de MAR é bem similar ao do índice de EAR. Isso porque a função MAR foi inspirada no EAR e descrita por Rishav Agarwal. Ambos os cálculos têm o mesmo objetivo: quantificar o nível de abertura.\n",
    "\n",
    "MAR é uma sigla para Mouth Aspect Ratio e consegue medir o nível de abertura da boca através do cálculo das distâncias euclidianas. Os pontos a serem coletados são: `82, 87, 13, 14, 312, 317, 78 e 308` e se localizam no lábio superior, inferior e nas extremidades, como mostrado abaixo:\n",
    "\n",
    "$$MAR = \\Large \\frac{||p_82-p_87||+||p_13-p_14||+||p_312-p_317||}{2*||p_78-p_308||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Funtions Ultils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_ear(face, p_eye_right, p_eye_left):\n",
    "    try:\n",
    "        face = np.array([[coord.x, coord.y] for coord in face]) \n",
    "        face_left  = face[p_eye_left,  :]\n",
    "        face_right = face[p_eye_right, :]\n",
    "\n",
    "        ear_left = (np.linalg.norm(face_left[0] - face_left[1]) + np.linalg.norm(face_left[2] - face_left[3]) \n",
    "                                                        / (2*(np.linalg.norm(face_left[4] - face_left[5]))))\n",
    "\n",
    "\n",
    "        ear_right = (np.linalg.norm(face_right[0] - face_right[1]) + np.linalg.norm(face_right[2] - face_right[3]) \n",
    "                                                        / (2*(np.linalg.norm(face_right[4] - face_right[5]))))\n",
    "        \n",
    "    except:\n",
    "        ear_left = 0\n",
    "        ear_right = 0\n",
    "\n",
    "    mean_ear = (ear_left + ear_right) / 2\n",
    "    return mean_ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que calcula as coordenadas de um membro (olhos e boca)\n",
    "def coord_calculation(face, frame, p_coord, lenght, width):\n",
    "    for id_coord, coord_xyz in enumerate(face):\n",
    "        if id_coord in p_coord:\n",
    "            coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x,coord_xyz.y, lenght, width)\n",
    "            cv2.circle(frame, coord_cv, 2, (255,0,0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_mar(face, p_mouth):\n",
    "    try:\n",
    "        face = np.array([[coord.x, coord.y] for coord in face])\n",
    "        face_mouth = face[p_mouth, :]\n",
    "        \n",
    "        mar = (np.linalg.norm(face_mouth[0]-face_mouth[1]) + np.linalg.norm(face_mouth[2]-face_mouth[3]) + \n",
    "               + np.linalg.norm(face_mouth[4]-face_mouth[5])) / (2*(+ np.linalg.norm(face_mouth[6]-face_mouth[7]))) \n",
    "    except:\n",
    "        mar = 0.0\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Executing code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coleta os pontos no rosto \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# coleta a solução do facemesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eye_left = [385, 380, 387, 373, 362, 263]\n",
    "p_eye_right = [160, 144, 158, 153, 33, 133]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessa célula, temos o p_boca, variável que guardará a lista, \n",
    "# igual aos valores dos pontos. Vamos rodar essa célula para que \n",
    "# a variável seja criada.\n",
    "p_mouth = [82, 87, 13, 14, 312, 317, 78, 308]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[385, 380, 387, 373, 362, 263, 160, 144, 158, 153, 33, 133]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenar as coordenadas dos dois olhos\n",
    "p_eyes = p_eye_left + p_eye_right\n",
    "p_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ear_limiar = 0.18\n",
    "\n",
    "sleep = 0\n",
    "\n",
    "cam_option = -1\n",
    "\n",
    "cap = cv2.VideoCapture(cam_option)\n",
    "\n",
    "# realiza a chamada do método para a detecção da face\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"No cam frame\\n\")\n",
    "            continue\n",
    "        \n",
    "                 \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        output_facemesh = facemesh.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        width, lenght, _ = frame.shape\n",
    "        \n",
    "        try:    \n",
    "            for face_landmarks in output_facemesh.multi_face_landmarks:\n",
    "                # coleta os pontos correspondentes as coordenadas do rosto\n",
    "                mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec = mp_drawing.DrawingSpec(color=(255,102,102),thickness=1,circle_radius=1),\n",
    "                    connection_drawing_spec = mp_drawing.DrawingSpec(color=(102,204,0),thickness=1,circle_radius=1)),\n",
    "\n",
    "            face = face_landmarks.landmark\n",
    "            coord_calculation(face, frame, p_eyes, lenght, width)\n",
    "            coord_calculation(face, frame, p_mouth, lenght, width)\n",
    "\n",
    "       \n",
    "            ear = calculation_ear(face, p_eye_right, p_eye_left)\n",
    "            \n",
    "            #Desenha um retangulo preenchido\n",
    "            cv2.rectangle(frame, (0,1), (170, 90), (58,58,55), -1)\n",
    "            \n",
    "            # Adicionando texto\n",
    "            cv2.putText(frame, f\"EAR: {round(ear, 2)}\", (1, 24),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX,\n",
    "                        0.7, (255, 255, 255), 2)\n",
    "\n",
    "            mar = calculation_mar(face, p_mouth)\n",
    "            # Adicionando texto\n",
    "            cv2.putText(frame, f\"MAR: {round(mar, 2)}\", (1, 50),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX,\n",
    "                        0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            if ear < ear_limiar:\n",
    "                t_init = time.time() if sleep == 0 else t_init\n",
    "                sleep = 1\n",
    "                \n",
    "            if sleep == 1 and ear >= ear_limiar:\n",
    "                sleep = 0\n",
    "            t_final = time.time()\n",
    "            \n",
    "            _time = (t_final-t_init) if sleep == 1 else 0.0        \n",
    "            cv2.putText(frame, f\"Time: {round(_time, 3)}\", (1, 80),\n",
    "                                    cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                    0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            if _time >= 1.5:\n",
    "                cv2.rectangle(frame, (30, 400), (610, 452), (109, 233, 219), -1)\n",
    "                cv2.putText(frame, f'So many time with close eye!', (80, 435),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                0.85, (58, 58, 55), 1)\n",
    "\n",
    "                \n",
    "        except:             \n",
    "            pass\n",
    "        \n",
    "        cv2.imshow('CAM', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
